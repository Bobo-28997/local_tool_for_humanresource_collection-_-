# =====================================
# Streamlit App (V2) -> è½¬æ¢ä¸º Tkinter æ¡Œé¢åº”ç”¨
#
# ã€Calamine æ•´åˆç‰ˆã€‘
# - [æ–°] æ‰€æœ‰ pd.read_excel/pd.ExcelFile è°ƒç”¨å‡å·²åˆ‡æ¢åˆ° 'calamine' å¼•æ“
# - åŒ…å« Streamlit -> Tkinter çš„è½¬æ¢ (UI, çº¿ç¨‹ç­‰)
# - åŒ…å« pd.ExcelFile çš„ 'with' è¯­å¥ä¿®å¤ï¼Œé˜²æ­¢ "ä¸€æ¬¡æ€§exe" æ–‡ä»¶é”å®šé—®é¢˜
# =====================================

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
import pandas as pd
from openpyxl import Workbook
from openpyxl.styles import PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows
import unicodedata, re
import time
import threading
import os
import traceback  # ç”¨äºæ›´è¯¦ç»†çš„é”™è¯¯æ—¥å¿—


# =====================================
# ğŸ› ï¸ æœªæ”¹å˜çš„å·¥å…·å‡½æ•° (æ¥è‡ª Streamlit è„šæœ¬)
# =====================================
# (è¿™äº›å‡½æ•°æ˜¯çº¯ Python/Pandas é€»è¾‘, æ— éœ€ä¿®æ”¹)

def normalize_colname(c):
    return str(c).strip().lower()


def find_col(df, keyword, exact=False):
    if df is None:
        return None
    key = keyword.strip().lower()
    for col in df.columns:
        cname = normalize_colname(col)
        if (exact and cname == key) or (not exact and key in cname):
            return col
    return None


def normalize_num(val):
    if pd.isna(val):
        return None
    s = str(val).replace(",", "").strip()
    if s in ["", "-", "nan"]:
        return None
    try:
        if "%" in s:
            s = s.replace("%", "")
            return float(s) / 100
        return float(s)
    except:
        return s


def normalize_text(val):
    if pd.isna(val):
        return ""
    s = str(val)
    s = re.sub(r'[\n\r\t ]+', '', s)
    s = s.replace('\u3000', '')
    s = ''.join(unicodedata.normalize('NFKC', ch) for ch in s)
    return s.lower().strip()


def detect_header_row(file, sheet_name):
    # <--- TKINTER MODIFICATION: è°ƒæ•´ä¸ºæ¥å—æ–‡ä»¶è·¯å¾„(path)
    try:
        # --- (ã€Calamine ä¿®æ”¹ã€‘) ---
        with pd.ExcelFile(file, engine='calamine') as xls:
            # (read_excel ä¼šè‡ªåŠ¨ç»§æ‰¿ calamine å¼•æ“)
            preview = pd.read_excel(xls, sheet_name=sheet_name, nrows=2, header=None)

        first_row = preview.iloc[0]
        total_cells = len(first_row)
        empty_like = sum(
            (pd.isna(x) or str(x).startswith("Unnamed") or str(x).strip() == "")
            for x in first_row
        )
        empty_ratio = empty_like / total_cells if total_cells > 0 else 0
        return 1 if empty_ratio >= 0.7 else 0
    except Exception as e:
        print(f"Error detecting header for {sheet_name}: {e}")
        return 0  # é»˜è®¤


def get_header_row(file, sheet_name):
    if any(k in sheet_name for k in ["èµ·ç§Ÿ", "äºŒæ¬¡"]):
        return 1
    return detect_header_row(file, sheet_name)


def normalize_contract_key(series: pd.Series) -> pd.Series:
    s = series.astype(str)
    s = s.str.replace(r"\.0$", "", regex=True)
    s = s.str.strip()
    s = s.str.upper()
    s = s.str.replace('ï¼', '-', regex=False)
    return s


def compare_series_vec(s_main, s_ref, compare_type='text', tolerance=0, multiplier=1):
    """
    (V3: å¢åŠ  'num_term' ç±»å‹)
    """
    merge_failed_mask = s_ref.isna()
    main_is_na = pd.isna(s_main) | (s_main.astype(str).str.strip().isin(["", "nan", "None"]))
    ref_is_na = pd.isna(s_ref) | (s_ref.astype(str).str.strip().isin(["", "nan", "None"]))
    both_are_na = main_is_na & ref_is_na

    errors = pd.Series(False, index=s_main.index)

    # 2. æ—¥æœŸæ¯”è¾ƒ
    if compare_type == 'date':
        d_main = pd.to_datetime(s_main, errors='coerce')
        d_ref = pd.to_datetime(s_ref, errors='coerce')

        valid_dates_mask = d_main.notna() & d_ref.notna()
        date_diff_mask = (d_main.dt.date != d_ref.dt.date)
        errors = valid_dates_mask & date_diff_mask

        one_is_date_one_is_not = (d_main.notna() & d_ref.isna() & ~ref_is_na) | \
                                 (d_main.isna() & ~main_is_na & d_ref.notna())
        errors |= one_is_date_one_is_not

    # 3. æ•°å€¼æ¯”è¾ƒ
    elif compare_type in ['num', 'num_term']:
        s_main_norm = s_main.apply(normalize_num)
        s_ref_norm = s_ref.apply(normalize_num)

        is_num_main = s_main_norm.apply(lambda x: isinstance(x, (int, float)))
        is_num_ref = s_ref_norm.apply(lambda x: isinstance(x, (int, float)))
        both_are_num = is_num_main & is_num_ref

        if both_are_num.any():
            diff = (s_main_norm[both_are_num] - s_ref_norm[both_are_num]).abs()

            if compare_type == 'num_term':
                errors.loc[both_are_num] = (diff >= 1.0)
            else:
                errors.loc[both_are_num] = (diff > (tolerance + 1e-6))

        one_is_num_one_is_not = (is_num_main & ~is_num_ref & ~ref_is_na) | \
                                (~is_num_main & ~main_is_na & is_num_ref)
        errors |= one_is_num_one_is_not

    # 4. æ–‡æœ¬æ¯”è¾ƒ
    else:  # compare_type == 'text'
        s_main_norm_text = s_main.apply(normalize_text)
        s_ref_norm_text = s_ref.apply(normalize_text)
        errors = (s_main_norm_text != s_ref_norm_text)

    # 5. æœ€ç»ˆé”™è¯¯é€»è¾‘
    final_errors = errors & ~both_are_na
    lookup_failure_mask = merge_failed_mask & ~main_is_na
    final_errors = final_errors & ~lookup_failure_mask

    return final_errors


# =====================================
# ğŸ–¥ï¸ Tkinter åº”ç”¨ä¸»ç±»
# =====================================

class AuditApp:
    def __init__(self, root):
        self.root = root
        # --- (ã€Calamine ä¿®æ”¹ã€‘) ---
        self.root.title("ğŸ“Š äººäº‹è–ªèµ„è¡¨è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿ-2 (è½»å¡)")
        self.root.geometry("800x700")

        self.style = ttk.Style()
        self.style.theme_use('clam')  # 'clam', 'alt', 'default', 'classic'

        # --- å®ä¾‹å˜é‡ ---
        self.uploaded_files = {}  # å­˜å‚¨æ–‡ä»¶è·¯å¾„, e.g. {'é¡¹ç›®ææˆ': 'path/to/file.xlsx', ...}
        self.output_dir = ""
        self.required_files = ["é¡¹ç›®ææˆ", "æ”¾æ¬¾æ˜ç»†", "äºŒæ¬¡æ˜ç»†", "äº§å“å°è´¦"]

        # --- GUI å¸ƒå±€ ---
        main_frame = ttk.Frame(root, padding="10")
        main_frame.pack(fill=tk.BOTH, expand=True)

        # --- 1. æ–‡ä»¶é€‰æ‹©åŒº ---
        input_frame = ttk.LabelFrame(main_frame, text="1. è¾“å…¥æ–‡ä»¶", padding="10")
        input_frame.pack(fill=tk.X, expand=False)

        self.select_files_button = ttk.Button(input_frame, text="é€‰æ‹© 4 ä¸ª Excel æ–‡ä»¶", command=self.select_files)
        self.select_files_button.pack(side=tk.LEFT, padx=(0, 10))

        self.file_status_label = ttk.Label(input_frame, text="å°šæœªé€‰æ‹©æ–‡ä»¶")
        self.file_status_label.pack(side=tk.LEFT, fill=tk.X, expand=True)

        # --- 2. è¾“å‡ºæ–‡ä»¶å¤¹é€‰æ‹©åŒº ---
        output_frame = ttk.LabelFrame(main_frame, text="2. è¾“å‡ºæ–‡ä»¶å¤¹", padding="10")
        output_frame.pack(fill=tk.X, expand=False, pady=5)

        self.select_output_dir_button = ttk.Button(output_frame, text="é€‰æ‹©æŠ¥å‘Šä¿å­˜ä½ç½®",
                                                   command=self.select_output_dir)
        self.select_output_dir_button.pack(side=tk.LEFT, padx=(0, 10))

        self.output_dir_label = ttk.Label(output_frame, text="å°šæœªé€‰æ‹©æ–‡ä»¶å¤¹")
        self.output_dir_label.pack(side=tk.LEFT, fill=tk.X, expand=True)

        # --- 3. æ‰§è¡ŒåŒº ---
        run_frame = ttk.Frame(main_frame, padding="10")
        run_frame.pack(fill=tk.X, expand=False)

        self.run_button = ttk.Button(run_frame, text="ğŸš€ å¼€å§‹å®¡æ ¸", command=self.run_audit_thread, state=tk.DISABLED)
        self.run_button.pack(fill=tk.X, expand=True)

        # --- 4. çŠ¶æ€å’Œè¿›åº¦åŒº ---
        status_frame = ttk.LabelFrame(main_frame, text="3. å®¡æ ¸çŠ¶æ€", padding="10")
        status_frame.pack(fill=tk.X, expand=False, pady=5)

        self.status_label = ttk.Label(status_frame, text="ç­‰å¾…å¼€å§‹...")
        self.status_label.pack(fill=tk.X, expand=True)

        self.progress_bar = ttk.Progressbar(status_frame, orient=tk.HORIZONTAL, length=100, mode='determinate')
        self.progress_bar.pack(fill=tk.X, expand=True, pady=5)

        # --- 5. æ—¥å¿—åŒº ---
        log_frame = ttk.LabelFrame(main_frame, text="4. è¿è¡Œæ—¥å¿—", padding="10")
        log_frame.pack(fill=tk.BOTH, expand=True, pady=5)

        self.log_widget = scrolledtext.ScrolledText(log_frame, wrap=tk.WORD, height=20, state=tk.DISABLED)
        self.log_widget.pack(fill=tk.BOTH, expand=True)

        # å®šä¹‰æ—¥å¿—é¢œè‰²
        self.log_widget.tag_config('INFO', foreground='black')
        self.log_widget.tag_config('SUCCESS', foreground='green')
        self.log_widget.tag_config('WARNING', foreground='orange')
        self.log_widget.tag_config('ERROR', foreground='red', font=('Helvetica', '9', 'bold'))

    # =====================================
    # ğŸ–¥ï¸ GUI äº¤äº’æ–¹æ³•
    # =====================================

    def _log(self, message, level='INFO'):
        """çº¿ç¨‹å®‰å…¨çš„æ—¥å¿—æ›´æ–°"""
        self.root.after(0, self.update_log_widget, message, level)

    def update_log_widget(self, message, level):
        self.log_widget.config(state=tk.NORMAL)
        self.log_widget.insert(tk.END, f"{message}\n", level.upper())
        self.log_widget.see(tk.END)  # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        self.log_widget.config(state=tk.DISABLED)

    def _update_status(self, text):
        """çº¿ç¨‹å®‰å…¨çš„çŠ¶æ€æ ‡ç­¾æ›´æ–°"""
        self.root.after(0, self.status_label.config, {'text': text})

    def _update_progress(self, value):
        """çº¿ç¨‹å®‰å…¨çš„è¿›åº¦æ¡æ›´æ–° (value: 0.0 to 1.0)"""
        self.root.after(0, self.progress_bar.config, {'value': value * 100})

    def _set_gui_state(self, is_running):
        """çº¿ç¨‹å®‰å…¨åœ°åˆ‡æ¢æŒ‰é’®çŠ¶æ€"""
        self.root.after(0, self.toggle_buttons, is_running)

    def toggle_buttons(self, is_running):
        state = tk.DISABLED if is_running else tk.NORMAL
        self.select_files_button.config(state=state)
        self.select_output_dir_button.config(state=state)
        if not is_running and self.check_ready(silent=True):
            self.run_button.config(state=tk.NORMAL)
        else:
            self.run_button.config(state=tk.DISABLED)

    def check_ready(self, silent=False):
        """æ£€æŸ¥æ‰€æœ‰æ¡ä»¶æ˜¯å¦æ»¡è¶³ï¼Œä»¥å¯ç”¨â€œå¼€å§‹å®¡æ ¸â€æŒ‰é’®"""
        ready = len(self.uploaded_files) == len(self.required_files) and self.output_dir
        if ready:
            self.run_button.config(state=tk.NORMAL)
            if not silent:
                self._log("âœ… æ‰€æœ‰æ–‡ä»¶å’Œè¾“å‡ºç›®å½•å·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å®¡æ ¸ã€‚", "SUCCESS")
        else:
            self.run_button.config(state=tk.DISABLED)
        return ready

    def select_files(self):
        self.uploaded_files = {}  # é‡ç½®

        file_paths = filedialog.askopenfilenames(
            title=f"è¯·é€‰æ‹©æ‰€æœ‰ {len(self.required_files)} ä¸ªæ–‡ä»¶",
            filetypes=[("Excel files", "*.xlsx *.xls")]
        )

        if not file_paths:
            self.file_status_label.config(text="æœªé€‰æ‹©æ–‡ä»¶")
            self.check_ready()
            return

        found_count = 0
        missing_files = list(self.required_files)  # å¤åˆ¶ä¸€ä»½

        for keyword in self.required_files:
            found_for_keyword = False
            for path in file_paths:
                filename = os.path.basename(path)
                if keyword in filename:
                    self.uploaded_files[keyword] = path
                    found_count += 1
                    if keyword in missing_files:
                        missing_files.remove(keyword)
                    found_for_keyword = True
                    break  # ä¸€ä¸ªå…³é”®å­—åªåŒ¹é…ä¸€ä¸ªæ–‡ä»¶

        self.file_status_label.config(
            text=f"å·²é€‰æ‹© {found_count} / {len(self.required_files)} ä¸ªæ–‡ä»¶ã€‚"
        )

        if missing_files:
            self._log(f"âš ï¸ ä»ç¼ºå°‘æ–‡ä»¶: {', '.join(missing_files)}", "WARNING")

        self.check_ready()

    def select_output_dir(self):
        dir_path = filedialog.askdirectory(title="é€‰æ‹©æŠ¥å‘Šä¿å­˜çš„æ–‡ä»¶å¤¹")
        if dir_path:
            self.output_dir = dir_path
            self.output_dir_label.config(text=f"å°†ä¿å­˜åˆ°: {dir_path}")
        else:
            self.output_dir = ""
            self.output_dir_label.config(text="å°šæœªé€‰æ‹©æ–‡ä»¶å¤¹")
        self.check_ready()

    def run_audit_thread(self):
        """â€œå¼€å§‹å®¡æ ¸â€æŒ‰é’®çš„å…¥å£ï¼Œå¯åŠ¨ä¸€ä¸ªæ–°çº¿ç¨‹"""
        self._set_gui_state(is_running=True)
        self.log_widget.config(state=tk.NORMAL)
        self.log_widget.delete('1.0', tk.END)  # æ¸…ç©ºæ—¥å¿—
        self.log_widget.config(state=tk.DISABLED)

        self._log("ğŸš€ å®¡æ ¸ä»»åŠ¡å¼€å§‹...", "INFO")

        # å¯åŠ¨åå°çº¿ç¨‹
        threading.Thread(target=self.run_audit_logic, daemon=True).start()

    # =====================================
    # ğŸ§® æ ¸å¿ƒå®¡æ ¸é€»è¾‘ (ç§»æ¤è‡ª Streamlit)
    # =====================================

    def prepare_one_ref_df(self, ref_df, ref_contract_col, required_cols, prefix):
        if ref_df is None:
            self._log(f"âš ï¸ å‚è€ƒæ–‡ä»¶ '{prefix}' æœªåŠ è½½ (df is None)ã€‚", "WARNING")
            return pd.DataFrame(columns=['__KEY__'])

        if ref_contract_col is None:
            self._log(f"âš ï¸ åœ¨ {prefix} å‚è€ƒè¡¨ä¸­æœªæ‰¾åˆ°'åˆåŒ'åˆ—ï¼Œè·³è¿‡æ­¤æ•°æ®æºã€‚", "WARNING")
            return pd.DataFrame(columns=['__KEY__'])

        cols_to_extract = []
        col_mapping = {}

        for col_kw in required_cols:
            actual_col = find_col(ref_df, col_kw)

            if actual_col:
                cols_to_extract.append(actual_col)
                col_mapping[actual_col] = f"ref_{prefix}_{col_kw}"
            else:
                self._log(f"âš ï¸ åœ¨ {prefix} å‚è€ƒè¡¨ä¸­æœªæ‰¾åˆ°åˆ— (å…³é”®å­—: '{col_kw}')", "WARNING")

        if not cols_to_extract:
            self._log(f"âš ï¸ åœ¨ {prefix} å‚è€ƒè¡¨ä¸­æœªæ‰¾åˆ°ä»»ä½•æ‰€éœ€å­—æ®µï¼Œè·³è¿‡ã€‚", "WARNING")
            return pd.DataFrame(columns=['__KEY__'])

        cols_to_extract.append(ref_contract_col)
        cols_to_extract_unique = list(set(cols_to_extract))
        valid_cols = [col for col in cols_to_extract_unique if col in ref_df.columns]
        std_df = ref_df[valid_cols].copy()

        std_df['__KEY__'] = normalize_contract_key(std_df[ref_contract_col])
        std_df = std_df.rename(columns=col_mapping)
        final_cols = ['__KEY__'] + list(col_mapping.values())
        final_cols_in_df = [col for col in final_cols if col in std_df.columns]
        std_df = std_df[final_cols_in_df]
        std_df = std_df.drop_duplicates(subset=['__KEY__'], keep='first')
        return std_df

    def audit_sheet_vec(self, sheet_name, xls_main, main_file_path, all_std_dfs, mapping_rules_vec):

        try:
            # (æ³¨æ„: get_header_row ä»ç„¶éœ€è¦ main_file_path æ¥è¯»å–é¢„è§ˆ)
            # (å®ƒå†…éƒ¨çš„ pd.ExcelFile å·²è¢«ä¿®æ”¹ä¸º calamine)
            header_offset = get_header_row(main_file_path, sheet_name)

            # (xls_main å·²ä½¿ç”¨ calamine æ‰“å¼€, æ­¤å¤„è‡ªåŠ¨ç»§æ‰¿)
            main_df = pd.read_excel(xls_main, sheet_name=sheet_name, header=header_offset)

            self._log(f"ğŸ“˜ å®¡æ ¸ä¸­ï¼š{sheet_name}ï¼ˆheader={header_offset}ï¼‰", "INFO")

            contract_col_main = find_col(main_df, "åˆåŒ")
            if not contract_col_main:
                self._log(f"âŒ {sheet_name} ä¸­æœªæ‰¾åˆ°â€œåˆåŒâ€åˆ—ï¼Œå·²è·³è¿‡ã€‚", "ERROR")
                return None, 0

            main_df['__ROW_IDX__'] = main_df.index
            main_df['__KEY__'] = normalize_contract_key(main_df[contract_col_main])

            merged_df = main_df.copy()
            for std_df in all_std_dfs.values():
                if not std_df.empty:
                    merged_df = pd.merge(merged_df, std_df, on='__KEY__', how='left')

            total_errors = 0
            errors_locations = set()
            row_has_error = pd.Series(False, index=merged_df.index)

            self._update_progress(0)

            total_comparisons = len(mapping_rules_vec)
            current_comparison = 0

            for main_kw, comparisons in mapping_rules_vec.items():
                current_comparison += 1

                main_col = find_col(main_df, main_kw)
                if not main_col:
                    continue

                self._update_status(f"æ£€æŸ¥ã€Œ{sheet_name}ã€: {main_kw}...")

                field_error_mask = pd.Series(False, index=merged_df.index)

                for (ref_col, compare_type, tol, mult) in comparisons:
                    if ref_col not in merged_df.columns:
                        continue

                    s_main = merged_df[main_col]
                    s_ref = merged_df[ref_col]

                    skip_mask = pd.Series(False, index=merged_df.index)

                    if main_kw == "åŸå¸‚ç»ç†":
                        na_mask = pd.isna(s_ref)
                        str_val = s_ref.astype(str).str.strip().str.lower()
                        str_mask = str_val.isin(["", "nan", "none", "null", "0", "0.0"])
                        skip_mask = na_mask | str_mask

                    errors_mask = compare_series_vec(s_main, s_ref, compare_type, tol, mult)
                    final_errors_mask = errors_mask & ~skip_mask
                    field_error_mask |= final_errors_mask

                if field_error_mask.any():
                    total_errors += field_error_mask.sum()
                    row_has_error |= field_error_mask

                    bad_indices = merged_df[field_error_mask]['__ROW_IDX__']
                    for idx in bad_indices:
                        errors_locations.add((idx, main_col))

                self._update_progress(current_comparison / total_comparisons)

            self._update_status(f"ã€Œ{sheet_name}ã€æ¯”å¯¹å®Œæˆï¼Œæ­£åœ¨ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶...")

            # 5. === å¿«é€Ÿå†™å…¥ Excel å¹¶æ ‡æ³¨ ===
            wb = Workbook()
            ws = wb.active
            red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
            yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")

            original_cols_list = list(main_df.drop(columns=['__ROW_IDX__', '__KEY__']).columns)
            col_name_to_idx = {name: i + 1 for i, name in enumerate(original_cols_list)}

            if header_offset > 0:
                for _ in range(header_offset):
                    ws.append([""] * len(original_cols_list))

            for r in dataframe_to_rows(main_df[original_cols_list], index=False, header=True):
                ws.append(r)

            for (row_idx, col_name) in errors_locations:
                if col_name in col_name_to_idx:
                    excel_row = row_idx + 1 + header_offset + 1
                    excel_col = col_name_to_idx[col_name]
                    ws.cell(excel_row, excel_col).fill = red_fill

            if contract_col_main in col_name_to_idx:
                contract_col_excel_idx = col_name_to_idx[contract_col_main]
                error_row_indices = merged_df[row_has_error]['__ROW_IDX__']
                for row_idx in error_row_indices:
                    excel_row = row_idx + 1 + header_offset + 1
                    ws.cell(excel_row, contract_col_excel_idx).fill = yellow_fill

            # 6. (ä¿®æ”¹) å¯¼å‡ºåˆ°æ–‡ä»¶
            save_path_full = os.path.join(self.output_dir, f"{sheet_name}_å®¡æ ¸æ ‡æ³¨ç‰ˆ.xlsx")
            wb.save(save_path_full)
            self._log(f"ğŸ“¥ æŠ¥å‘Šå·²ä¿å­˜: {save_path_full}", "SUCCESS")

            # 7. (ä¿®æ”¹) å¯¼å‡ºä»…å«é”™è¯¯è¡Œçš„æ–‡ä»¶ (å¸¦æ ‡çº¢)
            if row_has_error.any():
                try:
                    df_errors_only = merged_df.loc[row_has_error, original_cols_list].copy()
                    original_indices_with_error = merged_df.loc[row_has_error, '__ROW_IDX__']
                    original_idx_to_new_excel_row = {
                        original_idx: new_row_num
                        for new_row_num, original_idx in enumerate(original_indices_with_error, start=2)
                    }
                    wb_errors = Workbook()
                    ws_errors = wb_errors.active
                    for r in dataframe_to_rows(df_errors_only, index=False, header=True):
                        ws_errors.append(r)
                    for (original_row_idx, col_name) in errors_locations:
                        if original_row_idx in original_idx_to_new_excel_row:
                            new_row = original_idx_to_new_excel_row[original_row_idx]
                            if col_name in col_name_to_idx:
                                new_col = col_name_to_idx[col_name]
                                ws_errors.cell(row=new_row, column=new_col).fill = red_fill

                    save_path_errors = os.path.join(self.output_dir, f"{sheet_name}_ä»…é”™è¯¯è¡Œ_æ ‡çº¢.xlsx")
                    wb_errors.save(save_path_errors)
                    self._log(f"ğŸ“¥ ä»…é”™è¯¯è¡ŒæŠ¥å‘Šå·²ä¿å­˜: {save_path_errors}", "SUCCESS")

                except Exception as e:
                    self._log(f"âŒ ç”Ÿæˆâ€œä»…é”™è¯¯è¡Œâ€æ–‡ä»¶æ—¶å‡ºé”™: {e}", "ERROR")

            self._log(f"âœ… {sheet_name} å®¡æ ¸å®Œæˆï¼Œå…±å‘ç° {total_errors} å¤„é”™è¯¯", "SUCCESS")

            return main_df.drop(columns=['__ROW_IDX__', '__KEY__']), total_errors

        except Exception as e:
            self._log(f"âŒâŒâŒ åœ¨å¤„ç† {sheet_name} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", "ERROR")
            self._log(traceback.format_exc(), "ERROR")
            return None, 0

    def run_audit_logic(self):

        try:
            # =====================================
            # ğŸ› ï¸ æ–‡ä»¶è·¯å¾„å‡†å¤‡
            # =====================================

            main_file = self.uploaded_files.get("é¡¹ç›®ææˆ")
            ec_file = self.uploaded_files.get("äºŒæ¬¡æ˜ç»†")
            fk_file = self.uploaded_files.get("æ”¾æ¬¾æ˜ç»†")
            product_file = self.uploaded_files.get("äº§å“å°è´¦")

            if not all([main_file, ec_file, fk_file, product_file]):
                self._log("âŒ å†…éƒ¨é”™è¯¯ï¼šæ–‡ä»¶å­—å…¸ä¸å®Œæ•´ã€‚", "ERROR")
                return

            self._log("â„¹ï¸ -------------------------------", "INFO")
            self._log("â„¹ï¸ é˜¶æ®µ 1/3: æ­£åœ¨è¯»å–å¹¶é¢„å¤„ç†å‚è€ƒæ–‡ä»¶...", "INFO")

            # --- (ã€Calamine ä¿®æ”¹ã€‘) ---
            ec_df = pd.read_excel(ec_file, engine='calamine')
            product_df = pd.read_excel(product_file, engine='calamine')

            commission_df = None
            all_std_dfs = {}
            contract_col_comm = None

            # --- (ã€Calamine ä¿®æ”¹ã€‘) ---
            with pd.ExcelFile(fk_file, engine='calamine') as fk_xls:
                commission_sheets = [s for s in fk_xls.sheet_names if "ææˆ" in s]
                if not commission_sheets:
                    self._log("âŒ åœ¨ 'æ”¾æ¬¾æ˜ç»†' æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ä»»ä½•åŒ…å« 'ææˆ' çš„sheetï¼ç¨‹åºå·²åœæ­¢ã€‚", "ERROR")
                    return

                self._log(f"â„¹ï¸ æ­£åœ¨ä» 'æ”¾æ¬¾æ˜ç»†' åŠ è½½ {len(commission_sheets)} ä¸ª 'ææˆ' sheet...", "INFO")
                # (read_excel ä¼šè‡ªåŠ¨ç»§æ‰¿ calamine å¼•æ“)
                commission_df_list = [pd.read_excel(fk_xls, sheet_name=s) for s in commission_sheets]
                fk_commission_df = pd.concat(commission_df_list, ignore_index=True)

                fk_df = fk_commission_df
                commission_df = fk_commission_df

                contract_col_ec = find_col(ec_df, "åˆåŒ")
                contract_col_fk = find_col(fk_df, "åˆåŒ")
                contract_col_comm = find_col(commission_df, "åˆåŒ")
                contract_col_product = find_col(product_df, "åˆåŒ")

                mapping_rules_vec = {
                    "èµ·ç§Ÿæ—¥æœŸ": [("ref_ec_èµ·ç§Ÿæ—¥_å•†", 'date', 0, 1)],
                    "ç§Ÿèµæœ¬é‡‘": [("ref_fk_ç§Ÿèµæœ¬é‡‘", 'num', 0, 1)],
                    "æ”¶ç›Šç‡": [("ref_fk_XIRR", 'num', 0.005, 1)],
                    "æ“ä½œäºº": [("ref_fk_ææŠ¥äººå‘˜", 'text', 0, 1)],
                    "å®¢æˆ·ç»ç†": [("ref_fk_ææŠ¥äººå‘˜", 'text', 0, 1)],
                    "åŸå¸‚ç»ç†": [("ref_fk_åŸå¸‚ç»ç†", 'text', 0, 1)],
                    "å®ŒæˆäºŒæ¬¡äº¤æ¥æ—¶é—´": [("ref_ec_å‡ºæœ¬æµç¨‹æ—¶é—´", 'date', 0, 1)],
                    "å¹´åŒ–MIN": [("ref_product_å¹´åŒ–", 'num', 0.005, 1)],
                    "å¹´é™": [("ref_fk_ç§ŸèµæœŸé™", 'num_term', 0, 0)]
                }

                ec_cols = ["èµ·ç§Ÿæ—¥_å•†", "å‡ºæœ¬æµç¨‹æ—¶é—´"]
                fk_cols = ["ç§Ÿèµæœ¬é‡‘", "ææŠ¥äººå‘˜", "åŸå¸‚ç»ç†", "ç§ŸèµæœŸé™", "XIRR"]
                product_cols = ["å¹´åŒ–"]

                ec_std = self.prepare_one_ref_df(ec_df, contract_col_ec, ec_cols, "ec")
                fk_std = self.prepare_one_ref_df(fk_df, contract_col_fk, fk_cols, "fk")
                product_std = self.prepare_one_ref_df(product_df, contract_col_product, product_cols, "product")

                all_std_dfs = {"ec": ec_std, "fk": fk_std, "product": product_std}

            self._log("âœ… å‚è€ƒæ–‡ä»¶é¢„å¤„ç†å®Œæˆã€‚", "SUCCESS")

            # =====================================
            # ğŸ› ï¸ (ä¿®æ”¹) é˜¶æ®µ 2/3: æ‰§è¡Œä¸»æµç¨‹
            # =====================================
            self._log("â„¹ï¸ -------------------------------", "INFO")
            self._log("â„¹ï¸ é˜¶æ®µ 2/3: æ­£åœ¨æ‰§è¡Œä¸»æµç¨‹å®¡æ ¸...", "INFO")

            all_contracts_in_sheets = set()

            # --- (ã€Calamine ä¿®æ”¹ã€‘) ---
            with pd.ExcelFile(main_file, engine='calamine') as xls_main:
                target_sheets = [
                    s for s in xls_main.sheet_names
                    if any(k in s for k in ["èµ·ç§Ÿ", "äºŒæ¬¡", "å¹³å°å·¥", "ç‹¬ç«‹æ¶æ„", "ä½ä»·å€¼"])
                ]

                if not target_sheets:
                    self._log("âš ï¸ æœªåœ¨ 'é¡¹ç›®ææˆ' æ–‡ä»¶ä¸­æ‰¾åˆ°ä»»ä½•ç›®æ ‡ sheetã€‚", "WARNING")
                else:
                    for sheet_name in target_sheets:
                        df, _ = self.audit_sheet_vec(
                            sheet_name,
                            xls_main,
                            main_file,
                            all_std_dfs,
                            mapping_rules_vec
                        )

                        if df is not None:
                            col = find_col(df, "åˆåŒ")
                            if col:
                                normalized_contracts = normalize_contract_key(df[col].dropna())
                                all_contracts_in_sheets.update(normalized_contracts)

            self._log("âœ… ä¸»æµç¨‹å®¡æ ¸å®Œæˆã€‚", "SUCCESS")

            # =====================================
            # ğŸ› ï¸ é˜¶æ®µ 3/3: æ¼å¡«æ£€æµ‹
            # =====================================
            self._log("â„¹ï¸ -------------------------------", "INFO")
            self._log("â„¹ï¸ é˜¶æ®µ 3/3: æ­£åœ¨æ‰§è¡Œæ¼å¡«æ£€æµ‹...", "INFO")

            if commission_df is not None and contract_col_comm:
                commission_contracts = set(normalize_contract_key(commission_df[contract_col_comm].dropna()))

                missing_contracts = sorted(list(commission_contracts - all_contracts_in_sheets))

                self._log(f"ğŸ“‹ å…± {len(missing_contracts)} ä¸ªåˆåŒåœ¨å…­å¼ è¡¨ä¸­æœªå‡ºç°ã€‚", "INFO")

                if missing_contracts:
                    wb_miss = Workbook()
                    ws_miss = wb_miss.active
                    ws_miss.cell(1, 1, "æœªå‡ºç°åœ¨ä»»ä¸€è¡¨ä¸­çš„åˆåŒå·")
                    yellow = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
                    for i, cno in enumerate(missing_contracts, start=2):
                        ws_miss.cell(i, 1, cno).fill = yellow

                    save_path_missing = os.path.join(self.output_dir, "æ¼å¡«åˆåŒå·åˆ—è¡¨.xlsx")
                    wb_miss.save(save_path_missing)
                    self._log(f"ğŸ“¥ æ¼å¡«åˆåŒåˆ—è¡¨å·²ä¿å­˜: {save_path_missing}", "SUCCESS")
                else:
                    self._log("âœ… æ‰€æœ‰ææˆsheetåˆåŒå·å‡å·²å‡ºç°åœ¨å…­å¼ è¡¨ä¸­ï¼Œæ— æ¼å¡«ã€‚", "SUCCESS")

            else:
                self._log("âš ï¸ è·³è¿‡æ¼å¡«æ£€æµ‹ï¼Œå› ä¸º 'commission_df' æœªè¢«æˆåŠŸåŠ è½½ã€‚", "WARNING")

            self._log("ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰å®¡æ ¸ä»»åŠ¡å·²å®Œæˆï¼", "SUCCESS")

        except Exception as e:
            self._log(f"âŒâŒâŒ å‘ç”Ÿæœªæ•è·çš„ä¸¥é‡é”™è¯¯: {e}", "ERROR")
            self._log(traceback.format_exc(), "ERROR")
            self.root.after(0, messagebox.showerror, "ä¸¥é‡é”™è¯¯", f"å‘ç”Ÿæœªæ•è·çš„é”™è¯¯: \n{e}")

        finally:
            self._set_gui_state(is_running=False)
            self._update_status("å®¡æ ¸å®Œæˆã€‚")
            self._update_progress(0)
            self.root.after(0, messagebox.showinfo, "ä»»åŠ¡å®Œæˆ", "å®¡æ ¸å·²å…¨éƒ¨å®Œæˆï¼")


# =====================================
# ğŸš€ å¯åŠ¨åº”ç”¨
# =====================================
if __name__ == "__main__":
    root = tk.Tk()
    app = AuditApp(root)
    root.mainloop()